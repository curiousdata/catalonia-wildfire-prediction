{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports and config\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = \"data/iberfire_catalonia.nc\"  # adjust if needed\n",
    "OUT_NPZ = Path(\"data/minimal_cnn_samples.npz\")\n",
    "\n",
    "# choose very few variables and short time range\n",
    "FEATURE_VARS = [\"CLC_2006_forest_proportion\", \"wind_speed_mean\", \"t2m_mean\", \"RH_mean\", \"total_precipitation_mean\", \"is_holiday\"]  # change to actual names in ds\n",
    "LABEL_VAR = \"is_near_fire\"\n",
    "\n",
    "TIME_START = \"2018-06-01\"\n",
    "TIME_END   = \"2019-08-31\"  # one year\n",
    "SPATIAL_DOWNSAMPLE = 4      # keep every 4th pixel in y and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 11GB\n",
      "Dimensions:                     (y: 255, x: 281, time: 6241)\n",
      "Coordinates:\n",
      "  * x                           (x) float64 2kB 3.489e+06 3.49e+06 ... 3.769e+06\n",
      "  * y                           (y) float64 2kB 2.242e+06 ... 1.988e+06\n",
      "  * time                        (time) datetime64[ns] 50kB 2007-12-01 ... 202...\n",
      "Data variables:\n",
      "    CLC_2006_forest_proportion  (y, x) float32 287kB ...\n",
      "    wind_speed_mean             (time, y, x) float32 2GB ...\n",
      "    t2m_mean                    (time, y, x) float32 2GB ...\n",
      "    RH_mean                     (time, y, x) float32 2GB ...\n",
      "    total_precipitation_mean    (time, y, x) float32 2GB ...\n",
      "    is_holiday                  (time, y, x) float32 2GB ...\n",
      "    is_near_fire                (time, y, x) float32 2GB ...\n",
      "Attributes: (12/17)\n",
      "    title:                IberFire\n",
      "    description:          Datacube centered in Spain with 1km x 1km spatial r...\n",
      "    dimensions:           (y: 920, x: 1188, time: 6241)\n",
      "    spatial_resolution:   1km x 1km\n",
      "    temporal_resolution:  Daily\n",
      "    start_date:           2007-12-01\n",
      "    ...                   ...\n",
      "    geospatial_x_max:     3861734.3466\n",
      "    geospatial_y_min:     1573195.9911000002\n",
      "    geospatial_y_max:     2492195.9911\n",
      "    author:               Julen Ercibengoa Calvo\n",
      "    author_contact:       julen.ercibengoa@gmail.com, julen.ercibengoa@teknik...\n",
      "    creation_date:        2025-04-04\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: open dataset & inspect\n",
    "ds = xr.open_dataset(DATA_PATH)  # no chunks for now; we keep this small\n",
    "\n",
    "print(ds[FEATURE_VARS + [LABEL_VAR]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/_jtqhy053252zyb9r4y_h4yh0000gn/T/ipykernel_41219/2112922127.py:3: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(\"Selected time steps:\", time_sel.dims[\"time\"])\n",
      "/var/folders/lb/_jtqhy053252zyb9r4y_h4yh0000gn/T/ipykernel_41219/2112922127.py:8: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for t_idx in range(time_sel.dims[\"time\"]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected time steps: 457\n",
      "Xs shape: (457, 6, 64, 71) ys shape: (457, 64, 71)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: extract small tensor dataset\n",
    "time_sel = ds.sel(time=slice(TIME_START, TIME_END))\n",
    "print(\"Selected time steps:\", time_sel.dims[\"time\"])\n",
    "\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "for t_idx in range(time_sel.dims[\"time\"]):\n",
    "    # select at time index\n",
    "    frame = time_sel.isel(time=t_idx)\n",
    "\n",
    "    # features: list of [H,W]\n",
    "    feat_arrays = []\n",
    "    for v in FEATURE_VARS:\n",
    "        if v not in frame:\n",
    "            raise ValueError(f\"Variable {v} not found in dataset\")\n",
    "        arr = frame[v].values  # [H,W]\n",
    "        feat_arrays.append(arr)\n",
    "\n",
    "    # stack channels -> [C,H,W]\n",
    "    X = np.stack(feat_arrays, axis=0)\n",
    "\n",
    "    # label\n",
    "    if LABEL_VAR not in frame:\n",
    "        raise ValueError(f\"Label variable {LABEL_VAR} not found\")\n",
    "    y = frame[LABEL_VAR].values.astype(\"float32\")  # [H,W]\n",
    "\n",
    "    # optional: spatial downsample\n",
    "    X = X[:, ::SPATIAL_DOWNSAMPLE, ::SPATIAL_DOWNSAMPLE]\n",
    "    y = y[::SPATIAL_DOWNSAMPLE, ::SPATIAL_DOWNSAMPLE]\n",
    "\n",
    "    Xs.append(X)\n",
    "    ys.append(y)\n",
    "\n",
    "Xs = np.stack(Xs, axis=0)  # [N,C,H,W]\n",
    "ys = np.stack(ys, axis=0)  # [N,H,W]\n",
    "\n",
    "print(\"Xs shape:\", Xs.shape, \"ys shape:\", ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/minimal_cnn_samples.npz\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: simple normalization + save to disk\n",
    "# normalize each channel by global mean/std over this mini-dataset\n",
    "C = Xs.shape[1]\n",
    "for c in range(C):\n",
    "    mean = Xs[:, c].mean()\n",
    "    std = Xs[:, c].std()\n",
    "    if std < 1e-6:\n",
    "        std = 1.0\n",
    "    Xs[:, c] = (Xs[:, c] - mean) / std\n",
    "\n",
    "# binarize label if needed (0/1)\n",
    "ys_bin = (ys > 0.5).astype(\"float32\")\n",
    "\n",
    "OUT_NPZ.parent.mkdir(parents=True, exist_ok=True)\n",
    "np.savez_compressed(OUT_NPZ, X=Xs, y=ys_bin)\n",
    "print(\"Saved to\", OUT_NPZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 457\n",
      "Sample X shape: torch.Size([6, 64, 71]) y shape: torch.Size([1, 64, 71])\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: PyTorch dataset for the npz file\n",
    "class MinimalIberFireDataset(Dataset):\n",
    "    def __init__(self, npz_path):\n",
    "        data = np.load(npz_path)\n",
    "        self.X = data[\"X\"]          # [N,C,H,W]\n",
    "        self.y = data[\"y\"]          # [N,H,W]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = torch.from_numpy(self.X[idx]).float()        # [C,H,W]\n",
    "        y = torch.from_numpy(self.y[idx]).float()        # [H,W]\n",
    "        return X, y.unsqueeze(0)                         # [1,H,W]\n",
    "\n",
    "dataset = MinimalIberFireDataset(OUT_NPZ)\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "X0, y0 = dataset[0]\n",
    "print(\"Sample X shape:\", X0.shape, \"y shape:\", y0.shape)\n",
    "\n",
    "# Cell 6: create train/val splits and DataLoaders\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "N = len(dataset)\n",
    "n_train = int(0.8 * N)\n",
    "n_val = N - n_train\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyFireCNN(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: tiny CNN model\n",
    "class TinyFireCNN(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 1, 1),  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # [B,1,H,W]\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "in_channels = X0.shape[0]\n",
    "model = TinyFireCNN(in_channels).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | train_loss=0.5764 val_loss=0.4905 acc=0.995 prec=0.000 rec=0.000 f1=0.000\n",
      "Epoch 2 | train_loss=0.3877 val_loss=0.2849 acc=0.995 prec=0.000 rec=0.000 f1=0.000\n",
      "Epoch 3 | train_loss=0.2053 val_loss=0.1438 acc=0.995 prec=0.000 rec=0.000 f1=0.000\n",
      "Epoch 4 | train_loss=0.1063 val_loss=0.0820 acc=0.995 prec=0.000 rec=0.000 f1=0.000\n",
      "Epoch 5 | train_loss=0.0645 val_loss=0.0563 acc=0.995 prec=0.000 rec=0.000 f1=0.000\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: training loop\n",
    "def pixel_metrics(logits, y, thr=0.5):\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "        y = y.float()\n",
    "        tp = (preds * y).sum().item()\n",
    "        fp = (preds * (1 - y)).sum().item()\n",
    "        fn = ((1 - preds) * y).sum().item()\n",
    "        tn = (((1 - preds) * (1 - y))).sum().item()\n",
    "        eps = 1e-8\n",
    "        prec = tp / (tp + fp + eps)\n",
    "        rec = tp / (tp + fn + eps)\n",
    "        f1 = 2 * prec * rec / (prec + rec + eps)\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn + eps)\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= max(1, len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    acc_sum = prec_sum = rec_sum = f1_sum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            val_loss += loss.item()\n",
    "            a, p, r, f1 = pixel_metrics(logits, y)\n",
    "            acc_sum += a; prec_sum += p; rec_sum += r; f1_sum += f1\n",
    "    val_loss /= max(1, len(val_loader))\n",
    "    acc = acc_sum / max(1, len(val_loader))\n",
    "    prec = prec_sum / max(1, len(val_loader))\n",
    "    rec = rec_sum / max(1, len(val_loader))\n",
    "    f1 = f1_sum / max(1, len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch} | train_loss={train_loss:.4f} \"\n",
    "          f\"val_loss={val_loss:.4f} acc={acc:.3f} prec={prec:.3f} rec={rec:.3f} f1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pixels: 2076608 positives: 8787 negatives: 2067821 pos_ratio: 0.004231419699818165\n"
     ]
    }
   ],
   "source": [
    "# Check fire prevalence in the mini dataset\n",
    "import numpy as np\n",
    "\n",
    "data = np.load(\"data/minimal_cnn_samples.npz\")\n",
    "y = data[\"y\"]  # [N,H,W], already binarized\n",
    "\n",
    "pos = (y == 1).sum()\n",
    "neg = (y == 0).sum()\n",
    "print(\"Total pixels:\", y.size, \"positives:\", pos, \"negatives:\", neg, \"pos_ratio:\", pos / y.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
