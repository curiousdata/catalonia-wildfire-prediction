{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal ConvLSTM training on sharded NPZ produced by preprocess.ipynb\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -------- Dataset (streams shards) --------\n",
    "class ShardedNPZDataset(Dataset):\n",
    "    def __init__(self, split_dir: str):\n",
    "        self.split_dir = Path(split_dir)\n",
    "        man = self.split_dir / \"manifest.parquet\"\n",
    "        if man.exists():\n",
    "            df = pd.read_parquet(man)\n",
    "            self.shards = [(self.split_dir / r.shard, int(r.num_samples)) for _, r in df.iterrows()]\n",
    "        else:\n",
    "            self.shards = []\n",
    "            for p in sorted(self.split_dir.glob(\"shard_*.npz\")):\n",
    "                with np.load(p, mmap_mode=\"r\") as f:\n",
    "                    n = f[\"X\"].shape[0]\n",
    "                self.shards.append((p, n))\n",
    "        if not self.shards:\n",
    "            raise FileNotFoundError(f\"No shards found in {self.split_dir}\")\n",
    "        self.cum = np.cumsum([n for _, n in self.shards])\n",
    "        self._cache = {}  # per-worker cache of open npz\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.cum[-1])\n",
    "\n",
    "    def _open_npz(self, path: Path):\n",
    "        wid = torch.utils.data.get_worker_info()\n",
    "        key = (wid.id if wid else -1, str(path))\n",
    "        if key not in self._cache:\n",
    "            self._cache[key] = np.load(path, mmap_mode=\"r\", allow_pickle=False)\n",
    "        return self._cache[key]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        shard_idx = int(np.searchsorted(self.cum, idx, side=\"right\"))\n",
    "        base = 0 if shard_idx == 0 else int(self.cum[shard_idx - 1])\n",
    "        local_idx = int(idx - base)\n",
    "        path, _ = self.shards[shard_idx]\n",
    "        f = self._open_npz(path)\n",
    "        # X: [T,C,H,W], y: [H,W]\n",
    "        X = torch.from_numpy(f[\"X\"][local_idx]).float()\n",
    "        y = torch.from_numpy(f[\"y\"][local_idx]).float()  # 0/1\n",
    "        # Add channel to y for BCEWithLogits over [B,1,H,W]\n",
    "        return X, y.unsqueeze(0)\n",
    "\n",
    "# -------- ConvLSTM building blocks --------\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, kernel_size=3, bias=True):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.conv = nn.Conv2d(in_channels + hidden_channels,\n",
    "                              4 * hidden_channels,\n",
    "                              kernel_size,\n",
    "                              padding=padding,\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        h_prev, c_prev = state\n",
    "        combined = torch.cat([x, h_prev], dim=1)\n",
    "        gates = self.conv(combined)\n",
    "        i, f, o, g = torch.chunk(gates, 4, dim=1)\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        o = torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "        c = f * c_prev + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "    def init_state(self, B, H, W, device):\n",
    "        h = torch.zeros(B, self.hidden_channels, H, W, device=device)\n",
    "        c = torch.zeros(B, self.hidden_channels, H, W, device=device)\n",
    "        return h, c\n",
    "\n",
    "class StackedConvLSTM(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels_list=(32, 64), kernel_size=3):\n",
    "        super().__init__()\n",
    "        cells = []\n",
    "        ch_in = in_channels\n",
    "        for ch_hidden in hidden_channels_list:\n",
    "            cells.append(ConvLSTMCell(ch_in, ch_hidden, kernel_size))\n",
    "            ch_in = ch_hidden\n",
    "        self.cells = nn.ModuleList(cells)\n",
    "\n",
    "    def forward(self, x):  # x: [B,T,C,H,W]\n",
    "        B, T, C, H, W = x.shape\n",
    "        states = [cell.init_state(B, H, W, x.device) for cell in self.cells]\n",
    "        out = None\n",
    "        for t in range(T):\n",
    "            xt = x[:, t]  # [B,C,H,W]\n",
    "            for li, cell in enumerate(self.cells):\n",
    "                h, c = states[li]\n",
    "                h, c = cell(xt, (h, c))\n",
    "                states[li] = (h, c)\n",
    "                xt = h\n",
    "            out = xt  # last layer hidden at time t\n",
    "        return out  # [B, hidden_last, H, W]\n",
    "\n",
    "class ConvLSTMFireSeg(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=(32, 64)):\n",
    "        super().__init__()\n",
    "        self.backbone = StackedConvLSTM(in_channels, hidden_channels)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels[-1], 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, 1)  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B,T,C,H,W]\n",
    "        feats = self.backbone(x)\n",
    "        logits = self.head(feats)\n",
    "        return logits  # [B,1,H,W]\n",
    "\n",
    "# -------- Training utilities --------\n",
    "def pixel_metrics(logits, y, threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= threshold).float()\n",
    "        y = y.float()\n",
    "        tp = (preds * y).sum().item()\n",
    "        fp = (preds * (1 - y)).sum().item()\n",
    "        fn = ((1 - preds) * y).sum().item()\n",
    "        tn = (((1 - preds) * (1 - y))).sum().item()\n",
    "        eps = 1e-8\n",
    "        prec = tp / (tp + fp + eps)\n",
    "        rec = tp / (tp + fn + eps)\n",
    "        f1 = 2 * prec * rec / (prec + rec + eps)\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn + eps)\n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "def device_select():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if torch.backends.mps.is_available():  # macOS Metal\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def main():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data-root\", type=str, default=\"data/convlstm\")\n",
    "    parser.add_argument(\"--train-split\", type=str, default=\"train\")\n",
    "    parser.add_argument(\"--val-split\", type=str, default=\"val\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=4)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=4)\n",
    "    parser.add_argument(\"--pos-weight\", type=float, default=None, help=\"Positive class weight for BCEWithLogitsLoss\")\n",
    "    parser.add_argument(\"--amp\", action=\"store_true\", help=\"Enable mixed precision\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    root = Path(args.data_root)\n",
    "    cfg_path = root / \"config.json\"\n",
    "    if not cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"{cfg_path} not found. Run preprocessing first.\")\n",
    "    with open(cfg_path) as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    # Datasets/DataLoaders\n",
    "    train_dir = root / args.train_split\n",
    "    val_dir = root / args.val_split\n",
    "    train_ds = ShardedNPZDataset(str(train_dir))\n",
    "    val_ds = ShardedNPZDataset(str(val_dir))\n",
    "\n",
    "    # Peek one sample to infer shapes\n",
    "    X0, y0 = train_ds[0]  # X0: [T,C,H,W], y0: [1,H,W]\n",
    "    T, C, H, W = X0.shape\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.num_workers, pin_memory=True, persistent_workers=args.num_workers > 0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.num_workers, pin_memory=True, persistent_workers=args.num_workers > 0\n",
    "    )\n",
    "\n",
    "    # Model/Loss/Opt\n",
    "    device = device_select()\n",
    "    model = ConvLSTMFireSeg(in_channels=C, hidden_channels=(32, 64)).to(device)\n",
    "    pos_weight = torch.tensor([args.pos_weight], device=device) if args.pos_weight else None\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=args.amp and device.type == \"cuda\")\n",
    "\n",
    "    # MLflow (optional)\n",
    "    try:\n",
    "        import mlflow, mlflow.pytorch\n",
    "        mlflow.pytorch.autolog(log_models=True)\n",
    "        use_mlflow = True\n",
    "    except Exception:\n",
    "        use_mlflow = False\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_batches = 0\n",
    "        for X, y in train_loader:\n",
    "            # X: [B,T,C,H,W], y: [B,1,H,W]\n",
    "            X = X.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if scaler.is_enabled():\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(X)\n",
    "                    loss = criterion(logits, y)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "        train_loss = total_loss / max(1, total_batches)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        n_val_batches = 0\n",
    "        acc_sum = prec_sum = rec_sum = f1_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X = X.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "                val_loss += loss.item()\n",
    "                n_val_batches += 1\n",
    "                a, p, r, f1 = pixel_metrics(logits, y)\n",
    "                acc_sum += a; prec_sum += p; rec_sum += r; f1_sum += f1\n",
    "\n",
    "        val_loss = val_loss / max(1, n_val_batches)\n",
    "        acc = acc_sum / max(1, n_val_batches)\n",
    "        prec = prec_sum / max(1, n_val_batches)\n",
    "        rec = rec_sum / max(1, n_val_batches)\n",
    "        f1 = f1_sum / max(1, n_val_batches)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} val_loss={val_loss:.4f} acc={acc:.4f} prec={prec:.4f} rec={rec:.4f} f1={f1:.4f}\")\n",
    "\n",
    "        # Early stopping checkpoint\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            out_dir = Path(\"model\")\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save({\"model_state\": model.state_dict(),\n",
    "                        \"cfg\": cfg,\n",
    "                        \"T\": T, \"C\": C, \"H\": H, \"W\": W},\n",
    "                       out_dir / \"convlstm_best.pt\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
